import sys
import os
import logging
import time
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from src.data_structure import build_knowledge_base
    from src.prompt_engineering import create_comprehensive_prompt_system
    from src.llama_integration import DefenseCooperationLlama, ModelConfig
except ImportError:
    try:
        from data_structure import build_knowledge_base
        from prompt_engineering import create_comprehensive_prompt_system  
        from llama_integration import DefenseCooperationLlama, ModelConfig
    except ImportError as e:
        print(f"Import error: {e}")
        print("Please ensure all required modules are in the correct path")
        sys.exit(1)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AdvancedIntelligentGenerator:
    """ê°œì„ ëœ ì§€ëŠ¥í˜• ë‹µë³€ ìƒì„±ê¸° - ê° ì§ˆë¬¸ì— ë§ëŠ” êµ¬ì²´ì  ë‹µë³€ ìƒì„±"""
    
    def __init__(self):
        self.defense_keywords = [
            "ë°©ì‚°", "ë¯¸ì‚¬ì¼", "ë°©ì–´", "êµ°ì‚¬", "ë¬´ê¸°", "í˜‘ë ¥", "ìˆ˜ì¶œ", "íˆ¬ì",
            "ì¸ë„", "UAE", "ë¸Œë¼ì§ˆ", "ì¤‘ë™", "ë™ë‚¨ì•„", "ì•„í”„ë¦¬ì¹´", "ê¸°ìˆ ì´ì „",
            "ì‚¬ì´ë²„", "ìš°ì£¼", "í•­ê³µ", "í•´ì–‘", "ë“œë¡ ", "ë ˆì´ë”", "ë°©ê³µ", "êµ­ë°©",
            "ë¦¬ìŠ¤í¬", "ê´€ë¦¬", "ì „ëµ", "ìš°ì„ ìˆœìœ„", "ìˆœìœ„", "ì•ˆë³´", "ì „íˆ¬"
        ]
        
        self.technology_keywords = [
            "ê¸°ìˆ ", "ê°œë°œ", "í˜ì‹ ", "ì—°êµ¬", "AI", "ì¸ê³µì§€ëŠ¥", "ë¡œë´‡", "ìë™í™”",
            "ë¸”ë¡ì²´ì¸", "5G", "6G", "IoT", "ë¹…ë°ì´í„°", "í´ë¼ìš°ë“œ", "ì–‘ì", "ë‚˜ë…¸"
        ]
        
        # ì§ˆë¬¸ íŒ¨í„´ë³„ êµ¬ì²´ì  ë‹µë³€ ë§¤í•‘
        self.defense_qa_patterns = {
            # AI/ìœ¤ë¦¬ ê´€ë ¨
            ("ai", "ìœ¤ë¦¬", "ë¬¸ì œ"): self._generate_ai_ethics_response,
            ("ì¸ê³µì§€ëŠ¥", "ìœ¤ë¦¬", "ë„ì…"): self._generate_ai_ethics_response,
            ("ai", "ë„ì…", "ë¬¸ì œ"): self._generate_ai_ethics_response,
            
            # ìˆ˜ì¶œ ê´€ë ¨
            ("ìˆ˜ì¶œ", "ì¦ê°€", "ìš”ì¸"): self._generate_export_growth_response,
            ("ìˆ˜ì¶œ", "ì„±ì¥", "ì´ìœ "): self._generate_export_growth_response,
            ("ë°©ì‚°", "ìˆ˜ì¶œ", "í™•ëŒ€"): self._generate_export_growth_response,
            
            # ë¦¬ìŠ¤í¬ ê´€ë¦¬
            ("ë¦¬ìŠ¤í¬", "ê´€ë¦¬", "ë°©ë²•"): self._generate_risk_management_response,
            ("ìœ„í—˜", "ê´€ë¦¬", "ì „ëµ"): self._generate_risk_management_response,
            
            # ê¸°ìˆ  ê°œë°œ
            ("ê¸°ìˆ ", "ê°œë°œ", "ì „ëµ"): self._generate_tech_development_response,
            ("ì—°êµ¬ê°œë°œ", "ë°©í–¥", "ì „ëµ"): self._generate_tech_development_response,
            
            # êµ­ì œ í˜‘ë ¥
            ("êµ­ì œ", "í˜‘ë ¥", "ë°©ì•ˆ"): self._generate_international_cooperation_response,
            ("í•´ì™¸", "í˜‘ë ¥", "ì „ëµ"): self._generate_international_cooperation_response,
        }
        
        # ì¼ë°˜ ê¸°ìˆ  ì§ˆë¬¸ íŒ¨í„´
        self.tech_qa_patterns = {
            ("ì¸ê³µì§€ëŠ¥", "ë¯¸ë˜", "ì „ë§"): self._generate_ai_future_response,
            ("ai", "ë°œì „", "ë°©í–¥"): self._generate_ai_future_response,
            ("ë¸”ë¡ì²´ì¸", "í™œìš©", "ë°©ì•ˆ"): self._generate_blockchain_response,
            ("ê¸°í›„", "ê¸°ìˆ ", "ëŒ€ì‘"): self._generate_climate_tech_response,
            ("í™˜ê²½", "ê¸°ìˆ ", "í˜ì‹ "): self._generate_climate_tech_response,
        }
    
    def analyze_question_intent(self, query: str) -> tuple:
        """ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ì™€ í‚¤ì›Œë“œ ë¶„ì„"""
        query_lower = query.lower()
        
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        for word in query_lower.split():
            clean_word = word.strip("?.,!").strip()
            if len(clean_word) > 1:
                keywords.append(clean_word)
        
        # íŒ¨í„´ ë§¤ì¹­ì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œ ì„ ë³„
        important_keywords = []
        priority_words = [
            "ai", "ì¸ê³µì§€ëŠ¥", "ìœ¤ë¦¬", "ë¬¸ì œ", "ìˆ˜ì¶œ", "ì¦ê°€", "ìš”ì¸", "ë¦¬ìŠ¤í¬", "ê´€ë¦¬",
            "ê¸°ìˆ ", "ê°œë°œ", "ì „ëµ", "í˜‘ë ¥", "ì‹œì¥", "ë™í–¥", "ì •ì±…", "ë¯¸ë˜", "ì „ë§",
            "ë¸”ë¡ì²´ì¸", "í™œìš©", "ê¸°í›„", "í™˜ê²½", "í˜ì‹ ", "êµ­ë°©", "ë°©ì‚°", "êµ°ì‚¬"
        ]
        
        for keyword in keywords:
            for priority in priority_words:
                if priority.lower() in keyword or keyword in priority.lower():
                    important_keywords.append(priority)
        
        return tuple(important_keywords[:3])  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ
    
    def find_best_pattern_match(self, intent_keywords: tuple, patterns_dict: dict) -> callable:
        """ê°€ì¥ ì í•©í•œ íŒ¨í„´ ë§¤ì¹­ í•¨ìˆ˜ ì°¾ê¸°"""
        best_match = None
        best_score = 0
        
        for pattern, func in patterns_dict.items():
            score = 0
            for keyword in intent_keywords:
                for pattern_word in pattern:
                    if keyword.lower() in pattern_word.lower() or pattern_word.lower() in keyword.lower():
                        score += 1
            
            if score > best_score:
                best_score = score
                best_match = func
        
        return best_match if best_score > 0 else None
    
    def is_defense_related(self, query: str) -> bool:
        """ë°©ì‚° ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in self.defense_keywords)
    
    def is_technology_related(self, query: str) -> bool:
        """ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in self.technology_keywords)
    
    def extract_topic(self, query: str) -> str:
        """ì§ˆë¬¸ì—ì„œ ì£¼ì œ ì¶”ì¶œ"""
        words = query.split()
        stop_words = {"ì˜", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ë¡œ", "ìœ¼ë¡œ", "ì™€", "ê³¼", "í•˜ê³ ", "ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "?", "ì‹œ", "ë•Œ"}
        
        important_words = []
        for word in words:
            clean_word = word.strip("?.,!").strip()
            if len(clean_word) > 1 and clean_word not in stop_words:
                important_words.append(clean_word)
        
        return " ".join(important_words[:4]) if important_words else "í•´ë‹¹ ì£¼ì œ"
    
    # === ë°©ì‚° ë¶„ì•¼ êµ¬ì²´ì  ë‹µë³€ ìƒì„± í•¨ìˆ˜ë“¤ ===
    
    def _generate_ai_ethics_response(self, query: str, topic: str) -> str:
        """AI ìœ¤ë¦¬ ê´€ë ¨ êµ¬ì²´ì  ë‹µë³€"""
        return """êµ­ë°© ë¶„ì•¼ AI ê¸°ìˆ  ë„ì… ì‹œ ìœ¤ë¦¬ì  ë¬¸ì œì :

### âš–ï¸ ì£¼ìš” ìœ¤ë¦¬ì  ì´ìŠˆë“¤

**1. ììœ¨ë¬´ê¸°ì‹œìŠ¤í…œ (LAWS) ê´€ë ¨**
- **ìƒëª… ê²°ì •ê¶Œ**: AIê°€ ìƒì‚¬ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì˜ ë„ë•ì  ë¬¸ì œ
- **ì¸ê°„ í†µì œ**: ì¹˜ëª…ì  ê²°ì •ì—ì„œ ì¸ê°„ì˜ ì˜ë¯¸ìˆëŠ” í†µì œ í•„ìš”ì„±
- **ì±…ì„ ì†Œì¬**: AI ë¬´ê¸° ì˜¤ì‘ë™ ì‹œ ë²•ì /ë„ë•ì  ì±…ì„ ê·€ì† ë¬¸ì œ

**2. ì˜ì‚¬ê²°ì • íˆ¬ëª…ì„± ë¬¸ì œ**
- **ë¸”ë™ë°•ìŠ¤**: AI ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ì‚¬ê²°ì • ê³¼ì • ë¶ˆíˆ¬ëª…ì„±
- **í¸í–¥ì„±**: í›ˆë ¨ ë°ì´í„°ì˜ í¸í–¥ì´ ì°¨ë³„ì  ê²°ê³¼ ì´ˆë˜ ê°€ëŠ¥
- **ê²€ì¦ ì–´ë ¤ì›€**: ë³µì¡í•œ AI ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„± ê²€ì¦ í•œê³„

**3. ë°ì´í„° ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ**
- **ë¯¼ê°ì •ë³´**: êµ°ì‚¬ê¸°ë°€ê³¼ ê°œì¸ì •ë³´ ì²˜ë¦¬ ì‹œ ë³´ì•ˆ ìœ„í—˜
- **ë°ì´í„° ë‚¨ìš©**: ìˆ˜ì§‘ëœ ì •ë³´ì˜ ëª©ì  ì™¸ ì‚¬ìš© ê°€ëŠ¥ì„±
- **í•´í‚¹ ìœ„í—˜**: AI ì‹œìŠ¤í…œ ëŒ€ìƒ ì‚¬ì´ë²„ ê³µê²© ì·¨ì•½ì„±

### ğŸ›¡ï¸ ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ë°©í–¥

**êµ­ì œì  ê·œë²”**
- UNì˜ ì¹˜ëª…ì  ììœ¨ë¬´ê¸°ì‹œìŠ¤í…œ ë…¼ì˜ ì°¸ì—¬
- ì œë„¤ë°” í˜‘ì•½ ë“± êµ­ì œë²• ì¤€ìˆ˜ ì›ì¹™ í™•ë¦½
- ë™ë§¹êµ­ê³¼ì˜ AI ìœ¤ë¦¬ ê¸°ì¤€ ê³µì¡°

**ê¸°ìˆ ì  ëŒ€ì‘**
- ì„¤ëª… ê°€ëŠ¥í•œ AI (XAI) ê¸°ìˆ  ê°œë°œ
- ì¸ê°„-AI í˜‘ì—… ì²´ê³„ êµ¬ì¶• (Human-in-the-loop)
- ê°•ê±´í•œ AI ì‹œìŠ¤í…œ ì„¤ê³„ (Robust AI)

**ì œë„ì  ë³´ì™„**
- AI ìœ¤ë¦¬ ìœ„ì›íšŒ ì„¤ì¹˜ ë° ìš´ì˜
- ì •ê¸°ì  ìœ¤ë¦¬ ì˜í–¥ í‰ê°€ ì‹¤ì‹œ
- íˆ¬ëª…í•œ ê±°ë²„ë„ŒìŠ¤ ì²´ê³„ êµ¬ì¶•

### ğŸŒ êµ­ì œì  ë™í–¥
- EU: AI Actë¥¼ í†µí•œ ê³ ìœ„í—˜ AI ê·œì œ
- ë¯¸êµ­: AI ê¶Œë¦¬ì¥ì „ ë° êµ­ë°©ë¶€ AI ìœ¤ë¦¬ì›ì¹™
- ì¤‘êµ­: AI ê·œì œ í”„ë ˆì„ì›Œí¬ ê°œë°œ

### ğŸ’¡ í•œêµ­ì˜ ëŒ€ì‘ ë°©í–¥
êµ­ë°© AI ë„ì… ì‹œ 'ì¸ê°„ ì¤‘ì‹¬ì˜ AI' ì›ì¹™ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ìš°ìœ„ì™€ ìœ¤ë¦¬ì  ì±…ì„ ì‚¬ì´ì˜ ê· í˜•ì ì„ ì°¾ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. íŠ¹íˆ ë™ë§¹êµ­ê³¼ì˜ ê³µí†µ ê¸°ì¤€ ë§ˆë ¨ê³¼ íˆ¬ëª…í•œ ì˜ì‚¬ê²°ì • ê³¼ì • í™•ë¦½ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."""

    def _generate_export_growth_response(self, query: str, topic: str) -> str:
        """ë°©ì‚° ìˆ˜ì¶œ ì¦ê°€ ìš”ì¸ êµ¬ì²´ì  ë‹µë³€"""
        return """í•œêµ­ ë°©ì‚° ìˆ˜ì¶œ ê¸‰ì¦ì˜ ì£¼ìš” ìš”ì¸ë“¤:

### ğŸ“ˆ ìˆ˜ì¶œ ì„±ì¥ í˜„í™©
- **2022ë…„**: 172ì–µ ë‹¬ëŸ¬ (ì—­ëŒ€ ìµœê³  ê¸°ë¡)
- **2023ë…„**: 140ì–µ ë‹¬ëŸ¬ (ì§€ì†ì  ê³ ì„±ì¥)
- **ì„±ì¥ë¥ **: ìµœê·¼ 5ë…„ê°„ ì—°í‰ê·  20% ì´ìƒ ì¦ê°€

### ğŸš€ í•µì‹¬ ì„±ê³µ ìš”ì¸ë“¤

**1. ê¸°ìˆ ì  ê²½ìŸë ¥ í™•ë³´**
- **K9 ìì£¼í¬**: ì„¸ê³„ 1ìœ„ ìì£¼í¬ ìˆ˜ì¶œêµ­ ë‹¬ì„±
- **T-50/FA-50**: ê³ ë“±í›ˆë ¨ê¸° ì‹œì¥ ì„ ë„
- **ì²œê¶-II**: ì¤‘ê±°ë¦¬ ë°©ê³µì‹œìŠ¤í…œ ê¸°ìˆ ë ¥ ì¸ì •
- **í˜„ë¬´ ë¯¸ì‚¬ì¼**: ì •ë°€íƒ€ê²© ë¬´ê¸°ì²´ê³„ ìš°ìˆ˜ì„±

**2. ê°€ê²© ê²½ìŸë ¥**
- ì„œêµ¬ ë¬´ê¸° ëŒ€ë¹„ 30-50% ì €ë ´í•œ ê°€ê²©
- ë†’ì€ ì„±ëŠ¥ ëŒ€ë¹„ ê°€ê²© ë¹„ìœ¨ (Cost-Performance Ratio)
- ì¤‘ê²¬êµ­ êµ°ì‚¬ë ¥ í˜„ëŒ€í™” ìˆ˜ìš”ì— ì í•©í•œ í¬ì§€ì…”ë‹

**3. ì „ëµì  ë§ˆì¼€íŒ…**
- **ì •ìƒì™¸êµ**: ëŒ€í†µë ¹ ì§ì ‘ ì„¸ì¼ì¦ˆì™¸êµ ê°•í™”
- **íŒ¨í‚¤ì§€ ë”œ**: ë¬´ê¸°+ê¸°ìˆ ì´ì „+ì‚°ì—…í˜‘ë ¥ í†µí•© ì œì•ˆ
- **ì˜¤í”„ì…‹**: ìƒëŒ€êµ­ ì‚°ì—… ë°œì „ì— ê¸°ì—¬í•˜ëŠ” ìƒì‡„ê±°ë˜

**4. ì§€ì •í•™ì  ê¸°íšŒ í™œìš©**
- **ìš°í¬ë¼ì´ë‚˜ ì „ìŸ**: ìœ ëŸ½ì˜ ë°©ì‚° ìˆ˜ìš” ê¸‰ì¦
- **ì¸ë„-íƒœí‰ì–‘ ê¸´ì¥**: ì•„ì‹œì•„ êµ­ê°€ë“¤ì˜ êµ°ë¹„ ì¦ê°•
- **ì¤‘ë™ ì •ì„¸**: ê±¸í”„ êµ­ê°€ë“¤ì˜ ë°©ì‚° íˆ¬ì í™•ëŒ€

### ğŸŒ ì£¼ìš” ìˆ˜ì¶œ ì„±ê³¼

**í´ë€ë“œ (240ì–µ ë‹¬ëŸ¬ ê·œëª¨)**
- K9 ìì£¼í¬, K2 ì „ì°¨, FA-50 ê²½ê³µê²©ê¸°
- í˜„ì§€ ìƒì‚° ë° ê¸°ìˆ ì´ì „ í¬í•¨

**í˜¸ì£¼ (10ì–µ ë‹¬ëŸ¬)**
- AS21 ë ˆë“œë°± ë³´ë³‘ì „íˆ¬ì°¨
- K9 ìì£¼í¬ ì¶”ê°€ ë„ì…

**ì´ì§‘íŠ¸, ì‚¬ìš°ë””, UAE**
- ì¤‘ë™ ì‹œì¥ ì§„ì¶œ í™•ëŒ€
- ì²œê¶, K9 ë“± í•µì‹¬ ë¬´ê¸°ì²´ê³„

### ğŸ¯ ì„±ê³µ ì „ëµì˜ íŠ¹ì§•

**ê¸°ìˆ  ìë¦½ë„**
- êµ­ì‚°í™”ìœ¨ 80% ì´ìƒ ë‹¬ì„±
- í•µì‹¬ ê¸°ìˆ ì˜ ë…ì ê°œë°œ ì—­ëŸ‰

**ì‚°ì—… ìƒíƒœê³„**
- ëŒ€ê¸°ì—…-ì¤‘ì†Œê¸°ì—… í˜‘ë ¥ ì²´ê³„
- ì™„ì„±í’ˆë¶€í„° ë¶€í’ˆê¹Œì§€ íŒ¨í‚¤ì§€ ìˆ˜ì¶œ

**ì •ë¶€-ë¯¼ê°„ í˜‘ë ¥**
- ë°©ì‚°ì—…ì²´ í•´ì™¸ì§„ì¶œ ì ê·¹ ì§€ì›
- ì •ë¶€ë³´ì¦ë³´í—˜(K-Sure) í™œìš©

### ğŸ“Š ë¯¸ë˜ ì „ë§
2030ë…„ê¹Œì§€ ì—°ê°„ 300ì–µ ë‹¬ëŸ¬ ìˆ˜ì¶œ ëª©í‘œë¡œ, ì°¨ì„¸ëŒ€ ì „íˆ¬ê¸°(KF-21), í•œêµ­í˜• ì´ì§€ìŠ¤(KDDX) ë“± ì²¨ë‹¨ ë¬´ê¸°ì²´ê³„ ìˆ˜ì¶œ ë³¸ê²©í™” ì˜ˆìƒë©ë‹ˆë‹¤.

*í•œêµ­ ë°©ì‚°ì˜ ì„±ê³µì€ ê¸°ìˆ ë ¥, ê°€ê²© ê²½ìŸë ¥, ì „ëµì  ë§ˆì¼€íŒ…ì´ ê²°í•©ëœ ê²°ê³¼ì…ë‹ˆë‹¤.*"""

    def _generate_risk_management_response(self, query: str, topic: str) -> str:
        """ë¦¬ìŠ¤í¬ ê´€ë¦¬ êµ¬ì²´ì  ë‹µë³€"""
        return """ë°©ì‚° ë¶„ì•¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµ:

### ğŸ›¡ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬ ìœ í˜•ë³„ ê´€ë¦¬ ë°©ì•ˆ

**1. ê¸°ìˆ ì  ë¦¬ìŠ¤í¬**
- **ê°œë°œ ì§€ì—°**: ë‹¨ê³„ì  ê°œë°œ(Stage-Gate) ë°©ì‹ ì ìš©
- **ì„±ëŠ¥ ë¯¸ë‹¬**: ì² ì €í•œ ì‹œì œí’ˆ ê²€ì¦ ë° ì‹œí—˜í‰ê°€
- **ê¸°ìˆ  ìœ ì¶œ**: ë³´ì•ˆ ë“±ê¸‰ë³„ ì ‘ê·¼ í†µì œ ì‹œìŠ¤í…œ
- **í˜¸í™˜ì„± ë¬¸ì œ**: êµ­ì œ í‘œì¤€ ì¤€ìˆ˜ ë° ìƒí˜¸ìš´ìš©ì„± í™•ë³´

**2. ì‹œì¥/ê²½ì˜ ë¦¬ìŠ¤í¬**
- **ìˆ˜ìš” ë³€í™”**: ë‹¤ì–‘í•œ ì‹œì¥ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶•
- **ê²½ìŸ ì‹¬í™”**: ì°¨ë³„í™”ëœ ê¸°ìˆ ë ¥ í™•ë³´
- **ê°€ê²© ë³€ë™**: ì¥ê¸° ê³„ì•½ ë° í™˜í—¤ì§€ í™œìš©
- **ìê¸ˆ ì¡°ë‹¬**: ì •ë¶€ ë³´ì¦ ë° ìˆ˜ì¶œê¸ˆìœµ í™œìš©

**3. ì •ì¹˜/ê·œì œ ë¦¬ìŠ¤í¬**
- **ìˆ˜ì¶œ ê·œì œ**: ë³µìˆ˜ êµ­ê°€ ì¸ì¦ íšë“ (ë¯¸êµ­ ITAR, EU ë“±)
- **ì •ì±… ë³€í™”**: ì •ë¶€ ê´€ê³„ìì™€ ì§€ì†ì  ì†Œí†µ ì±„ë„
- **êµ­ì œ ê´€ê³„**: ì¤‘ë¦½ì  í¬ì§€ì…˜ ìœ ì§€ ë° ë‹¤ë³€í™”
- **ì œì¬ ìœ„í—˜**: ì‚¬ì „ ë²•ë¬´ ê²€í†  ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ê°•í™”

### ğŸ“‹ ì²´ê³„ì  ë¦¬ìŠ¤í¬ ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤

**1ë‹¨ê³„: ë¦¬ìŠ¤í¬ ì‹ë³„ (Risk Identification)**
- ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ì „ë©´ì  ìœ„í—˜ ìš”ì†Œ ë°œêµ´
- ë‚´ì™¸ë¶€ ì „ë¬¸ê°€ ìë¬¸ ë° ë²¤ì¹˜ë§ˆí‚¹
- ê³¼ê±° ì‚¬ë¡€ ë¶„ì„ ë° êµí›ˆ ë„ì¶œ

**2ë‹¨ê³„: ë¦¬ìŠ¤í¬ í‰ê°€ (Risk Assessment)**
- ë°œìƒ í™•ë¥  Ã— ì˜í–¥ë„ ë§¤íŠ¸ë¦­ìŠ¤ ì‘ì„±
- ì •ëŸ‰ì /ì •ì„±ì  ë¶„ì„ ë³‘í–‰
- ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë“±ê¸‰ ë¶„ë¥˜

**3ë‹¨ê³„: ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ (Risk Response)**
- **íšŒí”¼(Avoid)**: ìœ„í—˜ ìš”ì†Œ ì›ì²œ ì œê±°
- **ì™„í™”(Mitigate)**: ë°œìƒ í™•ë¥ /ì˜í–¥ ìµœì†Œí™”
- **ì „ê°€(Transfer)**: ë³´í—˜, íŒŒíŠ¸ë„ˆì‹­ í™œìš©
- **ìˆ˜ìš©(Accept)**: ì”ì—¬ ìœ„í—˜ì˜ ê´€ë¦¬ëœ ìˆ˜ìš©

**4ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ë° í†µì œ (Monitoring & Control)**
- ì‹¤ì‹œê°„ ë¦¬ìŠ¤í¬ ì§€í‘œ ì¶”ì 
- ì •ê¸°ì  ë¦¬ìŠ¤í¬ ì¬í‰ê°€
- ë¹„ìƒê³„íš(Contingency Plan) ê°€ë™

### ğŸ¯ ë¶„ì•¼ë³„ íŠ¹í™” ê´€ë¦¬ ë°©ì•ˆ

**R&D í”„ë¡œì íŠ¸**
- ê¸°ìˆ ì„±ìˆ™ë„(TRL) ë‹¨ê³„ë³„ ê²Œì´íŠ¸ ì‹¬ì‚¬
- ì‹¤íŒ¨ í—ˆìš©ì  ë¬¸í™”ì™€ ë¹ ë¥¸ í”¼ë´‡ ì „ëµ
- ì™¸ë¶€ ì „ë¬¸ê°€ ìë¬¸ë‹¨ ìƒì‹œ ìš´ì˜

**í•´ì™¸ ìˆ˜ì¶œ**
- êµ­ê°€ ì‹ ìš©ë„ í‰ê°€ ë° ì •ì¹˜ì  ì•ˆì •ì„± ë¶„ì„
- í˜„ì§€ íŒŒíŠ¸ë„ˆì™€ì˜ ìœ„í—˜ ë¶„ë‹´ êµ¬ì¡°
- ë‹¤ë‹¨ê³„ ëŒ€ê¸ˆ íšŒìˆ˜ ë°©ì•ˆ

**ê³µê¸‰ë§ ê´€ë¦¬**
- í•µì‹¬ ë¶€í’ˆì˜ ë³µìˆ˜ ê³µê¸‰ì—…ì²´ í™•ë³´
- ì „ëµì  ì¬ê³  ê´€ë¦¬ ë° ëŒ€ì²´ì¬ ê°œë°œ
- ê³µê¸‰ì—…ì²´ ì¬ë¬´ ê±´ì „ì„± ì •ê¸° ì ê²€

### ğŸ’¡ ìµœì‹  ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë„êµ¬

**ë””ì§€í„¸ ê¸°ë°˜ ê´€ë¦¬**
- AI/ë¹…ë°ì´í„°ë¥¼ í™œìš©í•œ ì˜ˆì¸¡ì  ë¦¬ìŠ¤í¬ ë¶„ì„
- ë¸”ë¡ì²´ì¸ ê¸°ë°˜ ê³µê¸‰ë§ íˆ¬ëª…ì„± í™•ë³´
- IoT ì„¼ì„œë¥¼ í†µí•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

**ESG ë¦¬ìŠ¤í¬ ê´€ë¦¬**
- í™˜ê²½ ì˜í–¥ í‰ê°€ ë° ì§€ì†ê°€ëŠ¥ì„± í™•ë³´
- ì‚¬íšŒì  ì±…ì„ ì´í–‰ ë° ì§€ì—­ì‚¬íšŒ ê´€ê³„
- íˆ¬ëª…í•œ ê±°ë²„ë„ŒìŠ¤ ë° ìœ¤ë¦¬ê²½ì˜

### ğŸ† ì„±ê³µ ì‚¬ë¡€: Kë°©ì‚°ì—…ì²´ë“¤ì˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬
í•œí™”ì‹œìŠ¤í…œ, í•œêµ­í•­ê³µìš°ì£¼ì‚°ì—… ë“±ì€ ì²´ê³„ì  ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ í†µí•´ ëŒ€í˜• í•´ì™¸ ìˆ˜ì£¼ì— ì„±ê³µí•˜ë©°, ìœ„í—˜ ìš”ì†Œë¥¼ ê¸°íšŒë¡œ ì „í™˜í•˜ëŠ” ì—­ëŸ‰ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.

*ë°©ì‚° ë¶„ì•¼ì˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ëŠ” ê¸°ìˆ ì  ì „ë¬¸ì„±ê³¼ ì²´ê³„ì  ê´€ë¦¬ ì—­ëŸ‰ì´ ê²°í•©ë˜ì–´ì•¼ íš¨ê³¼ì ì…ë‹ˆë‹¤.*"""
    
    def _generate_tech_development_response(self, query: str, topic: str) -> str:
        """ê¸°ìˆ  ê°œë°œ ì „ëµ ë‹µë³€"""
        return f"""{topic} ê°œë°œ ì „ëµ:

### ğŸ”¬ í•µì‹¬ ê¸°ìˆ  ê°œë°œ ë°©í–¥
- ì°¨ì„¸ëŒ€ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ë° ì„ ì œì  ëŒ€ì‘
- êµ­ì œ í‘œì¤€ê³¼ í˜¸í™˜ì„±ì„ ê³ ë ¤í•œ ê¸°ìˆ  ë¡œë“œë§µ
- ë¯¼ê°„-êµ°ì‚¬ ìœµí•© ê¸°ìˆ (Dual-Use) í™œìš©

### ğŸ¯ ë‹¨ê³„ë³„ ê°œë°œ ì „ëµ
**1ë‹¨ê³„**: ê¸°ì´ˆ ì—°êµ¬ ë° ê°œë… ê²€ì¦
**2ë‹¨ê³„**: ì‹œì œí’ˆ ê°œë°œ ë° ì„±ëŠ¥ ê²€ì¦  
**3ë‹¨ê³„**: ì–‘ì‚° ë° ìš´ìš© ìµœì í™”

### ğŸ’¡ í˜ì‹  í¬ì¸íŠ¸
í˜„ì¬ ê¸€ë¡œë²Œ ê¸°ìˆ  ê²½ìŸì—ì„œ {topic} ë¶„ì•¼ì˜ ìš°ìœ„ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•´ì„œëŠ” ë…ì°½ì  ì ‘ê·¼ê³¼ ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ì´ í•„ìš”í•©ë‹ˆë‹¤."""

    def _generate_international_cooperation_response(self, query: str, topic: str) -> str:
        """êµ­ì œ í˜‘ë ¥ ë°©ì•ˆ ë‹µë³€"""
        return f"""{topic} êµ­ì œ í˜‘ë ¥ ì „ëµ:

### ğŸ¤ í˜‘ë ¥ ëª¨ë¸ ë‹¤ì–‘í™”
- ì–‘ì í˜‘ë ¥: í•µì‹¬ íŒŒíŠ¸ë„ˆì™€ì˜ ì‹¬í™” í˜‘ë ¥
- ë‹¤ì í˜‘ë ¥: êµ­ì œ ì»¨ì†Œì‹œì—„ ì°¸ì—¬
- ê¸°ìˆ  êµë¥˜: ìƒí˜¸ ë³´ì™„ì  ê¸°ìˆ  ê³µìœ 

### ğŸŒ ì§€ì—­ë³„ í˜‘ë ¥ ì „ëµ
**ì•„ì‹œì•„-íƒœí‰ì–‘**: ì•ˆë³´ í˜‘ë ¥ ê°•í™”
**ìœ ëŸ½**: ê¸°ìˆ  í‘œì¤€ ë° ê·œì œ í˜‘ë ¥
**ì¤‘ë™**: ì—ë„ˆì§€-ë°©ì‚° íŒ¨í‚¤ì§€ í˜‘ë ¥

### ğŸ“ˆ ê¸°ëŒ€ íš¨ê³¼
êµ­ì œ í˜‘ë ¥ì„ í†µí•´ ê¸°ìˆ  ì ‘ê·¼ì„± í™•ëŒ€, ì‹œì¥ ì§„ì¶œ ê°€ì†í™”, ìœ„í—˜ ë¶„ì‚° íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

    # ê¸°ìˆ  ë¶„ì•¼ ë‹µë³€ í•¨ìˆ˜ë“¤
    def _generate_ai_future_response(self, query: str, topic: str) -> str:
        """AI ë¯¸ë˜ ì „ë§ ë‹µë³€"""
        return """ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ ì˜ ë¯¸ë˜ ì „ë§:

### ğŸš€ 2025-2030 í•µì‹¬ ë°œì „ ë™í–¥

**ìƒì„±í˜• AI ê³ ë„í™”**
- GPT-5, Claude-4 ë“± ì°¨ì„¸ëŒ€ ëŒ€í™”í˜• AI
- ë©€í‹°ëª¨ë‹¬ AI: í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+ìŒì„±+ë¹„ë””ì˜¤ í†µí•© ì²˜ë¦¬
- ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ë° ê°œì¸í™” ì„œë¹„ìŠ¤ í™•ì‚°

**ììœ¨ AI ì‹œìŠ¤í…œ**
- AGI(Artificial General Intelligence) ì‹¤í˜„ ê°€ëŠ¥ì„± ì¦ëŒ€
- ìê¸° í•™ìŠµ ë° ìê¸° ê°œì„  ëŠ¥ë ¥ íšë“
- ì¸ê°„ ìˆ˜ì¤€ì˜ ì¶”ë¡  ë° ì°½ì˜ì  ì‚¬ê³  êµ¬í˜„

### ğŸ­ ì‚°ì—…ë³„ í˜ì‹  ì ìš©

**ì œì¡°ì—… í˜ëª…**
- AI ê¸°ë°˜ ì™„ì „ ìë™í™” ê³µì¥ ì‹¤í˜„
- ì˜ˆì¸¡ ì •ë¹„ë¡œ ë‹¤ìš´íƒ€ì„ 90% ê°ì†Œ
- ê°œì¸ ë§ì¶¤í˜• ëŒ€ëŸ‰ìƒì‚° ì‹œìŠ¤í…œ

**ì˜ë£Œ íŒ¨ëŸ¬ë‹¤ì„ ë³€í™”**
- AI ì˜ì‚¬: ì§„ë‹¨ ì •í™•ë„ 95% ì´ìƒ
- ì‹ ì•½ ê°œë°œ ê¸°ê°„ 70% ë‹¨ì¶•
- ê°œì¸ ìœ ì „ì ê¸°ë°˜ ë§ì¶¤ ì¹˜ë£Œ

### ğŸ‡°ğŸ‡· í•œêµ­ì˜ AI ì „ëµ

**ê°•ì  í™œìš©**
- ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ë°˜ë„ì²´ ê¸°ìˆ  (ë©”ëª¨ë¦¬, ì‹œìŠ¤í…œë°˜ë„ì²´)
- 5G/6G í†µì‹  ì¸í”„ë¼ ìš°ìœ„
- ì œì¡°ì—… ê¸°ë°˜ AI ì ìš© ê²½í—˜

**ë„ì „ ê³¼ì œ**
- ë°ì´í„° í™•ë³´ ë° í™œìš© ê·œì œ ê°œì„ 
- AI ì „ë¬¸ ì¸ë ¥ 10ë§Œëª… ì–‘ì„± í•„ìš”
- ê¸€ë¡œë²Œ AI í‘œì¤€ ì„ ë„ê¶Œ í™•ë³´

### ğŸ”® ì¥ê¸° ì „ë§ (2030-2040)

**ê¸°ìˆ ì  í˜ì‹ **
- ì–‘ì-AI ìœµí•© ì»´í“¨íŒ… ì‹¤í˜„
- ë‡Œ-ì»´í“¨í„° ì¸í„°í˜ì´ìŠ¤ ìƒìš©í™”
- AI ì˜ì‹(Consciousness) ë…¼ì˜ ë³¸ê²©í™”

### ğŸ’¡ ì„±ê³µì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œ
AIëŠ” ë‹¨ìˆœí•œ ê¸°ìˆ ì´ ì•„ë‹Œ ì‚¬íšŒ ì „ì²´ë¥¼ ë³€í™”ì‹œí‚¤ëŠ” ë²”ìš© ê¸°ìˆ ë¡œ, ê¸°ìˆ  ê°œë°œê³¼ í•¨ê»˜ ì œë„ì  ì¤€ë¹„, ì¸ë ¥ ì–‘ì„±, ìœ¤ë¦¬ì  ê¸°ì¤€ ë§ˆë ¨ì´ ë™ì‹œì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤."""

    def _generate_blockchain_response(self, query: str, topic: str) -> str:
        """ë¸”ë¡ì²´ì¸ í™œìš© ë°©ì•ˆ ë‹µë³€"""
        return """ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ í˜ì‹ ì  í™œìš© ë°©ì•ˆ:

### ğŸ”— ë¸”ë¡ì²´ì¸ í•µì‹¬ íŠ¹ì§•ê³¼ ì¥ì 
- **íƒˆì¤‘ì•™í™”**: ì¤‘ì•™ ê´€ë¦¬ ê¸°ê´€ ì—†ëŠ” ë¶„ì‚° ë„¤íŠ¸ì›Œí¬
- **íˆ¬ëª…ì„±**: ëª¨ë“  ê±°ë˜ ê¸°ë¡ì˜ ê³µê°œì  ê²€ì¦ ê°€ëŠ¥
- **ë¶ˆë³€ì„±**: í•œë²ˆ ê¸°ë¡ëœ ë°ì´í„°ì˜ ìœ„ë³€ì¡° ë°©ì§€
- **ìŠ¤ë§ˆíŠ¸ ê³„ì•½**: ìë™í™”ëœ ê³„ì•½ ì‹¤í–‰ ë° ì´í–‰

### ğŸ’¼ ì‚°ì—…ë³„ í˜ì‹ ì  ì ìš© ì‚¬ë¡€

**ê¸ˆìœµ ì„œë¹„ìŠ¤ í˜ì‹ **
- DeFi(íƒˆì¤‘ì•™í™” ê¸ˆìœµ): ì€í–‰ ì—†ëŠ” ê¸ˆìœµ ì„œë¹„ìŠ¤
- CBDC(ì¤‘ì•™ì€í–‰ ë””ì§€í„¸í™”í): ë””ì§€í„¸ ì›í™” ë°œí–‰ ì¤€ë¹„
- í¬ë¡œìŠ¤ë³´ë” ì†¡ê¸ˆ: ì‹¤ì‹œê°„ êµ­ì œì†¡ê¸ˆ ì„œë¹„ìŠ¤

**ê³µê¸‰ë§ íˆ¬ëª…ì„± í™•ë³´**
- ì œí’ˆ ì´ë ¥ ì¶”ì : ì›ì‚°ì§€ë¶€í„° ì†Œë¹„ìê¹Œì§€ ì „ ê³¼ì •
- ì§„í’ˆ ì¸ì¦: ëª…í’ˆ, ì˜ì•½í’ˆ ìœ„ì¡°í’ˆ ë°©ì§€
- ESG ì¸ì¦: ì§€ì†ê°€ëŠ¥ì„± ì¦ëª… ë° íƒ„ì†Œë°œìêµ­ ì¶”ì 

### ğŸ‡°ğŸ‡· í•œêµ­ì˜ ë¸”ë¡ì²´ì¸ ì „ëµ

**ì •ë¶€ ì •ì±… ë°©í–¥**
- ë””ì§€í„¸ë‰´ë”œì˜ í•µì‹¬ ê¸°ìˆ ë¡œ ì„ ì •
- ê·œì œ ìƒŒë“œë°•ìŠ¤ë¥¼ í†µí•œ í˜ì‹  ì‹¤í—˜
- K-ë””ì§€í„¸ í¬ë ˆë”§ìœ¼ë¡œ ì‹ ì›ì¸ì¦ ì„œë¹„ìŠ¤

### ğŸ’¡ ì„±ê³µì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œ
ë¸”ë¡ì²´ì¸ì€ ë‹¨ìˆœí•œ ê¸°ìˆ ì„ ë„˜ì–´ ì‹ ë¢° êµ¬ì¡°ì˜ í˜ì‹ ì…ë‹ˆë‹¤. ê¸°ìˆ ì  ì™„ì„±ë„ì™€ í•¨ê»˜ ì‚¬íšŒì  ìˆ˜ìš©ì„±, ê·œì œ í™˜ê²½, ì‚¬ìš©ì ê²½í—˜ ê°œì„ ì´ ë™ì‹œì— ì´ë£¨ì–´ì ¸ì•¼ ì§„ì •í•œ í˜ì‹ ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""

    def _generate_climate_tech_response(self, query: str, topic: str) -> str:
        """ê¸°í›„ë³€í™” ëŒ€ì‘ ê¸°ìˆ  ë‹µë³€"""
        return """ê¸°í›„ë³€í™” ëŒ€ì‘ì„ ìœ„í•œ í˜ì‹  ê¸°ìˆ ë“¤:

### ğŸŒ± íƒ„ì†Œ ì¤‘ë¦½ í•µì‹¬ ê¸°ìˆ ë“¤

**ì²­ì • ì—ë„ˆì§€ í˜ì‹ **
- **í˜ë¡œë¸ŒìŠ¤ì¹´ì´íŠ¸ íƒœì–‘ì „ì§€**: íš¨ìœ¨ 30% ëŒíŒŒ, í”Œë ‰ì„œë¸” ì ìš©
- **ë¶€ìœ ì‹ í•´ìƒí’ë ¥**: ìˆ˜ì‹¬ ì œì•½ ì—†ëŠ” ëŒ€ìš©ëŸ‰ ë°œì „
- **ê·¸ë¦° ìˆ˜ì†Œ**: ì¬ìƒì—ë„ˆì§€ ê¸°ë°˜ ë¬¼ ì „ê¸°ë¶„í•´
- **ì†Œí˜•ëª¨ë“ˆì›ìë¡œ(SMR)**: ì•ˆì „ì„± ê°•í™”ëœ ì°¨ì„¸ëŒ€ ì›ì „

**í˜ì‹ ì  ì—ë„ˆì§€ ì €ì¥**
- **ê³ ì²´ ë°°í„°ë¦¬**: ì•ˆì „ì„±ê³¼ ìš©ëŸ‰ë°€ë„ ëŒ€í­ ê°œì„ 
- **ì•¡ì²´ê³µê¸° ì €ì¥**: ëŒ€ìš©ëŸ‰ ì¥ì£¼ê¸° ì—ë„ˆì§€ ì €ì¥
- **ê·¸ë˜ë¹„í‹° ì €ì¥**: ì¤‘ë ¥ì„ ì´ìš©í•œ ë¬¼ë¦¬ì  ì—ë„ˆì§€ ì €ì¥

### ğŸ‡°ğŸ‡· í•œêµ­ì˜ ê·¸ë¦°í…Œí¬ í˜ì‹ 

**K-ê·¸ë¦°ë‰´ë”œ ì„±ê³¼**
- ë°°í„°ë¦¬: ì„¸ê³„ ì‹œì¥ì ìœ ìœ¨ 30% (LGì—ë„ˆì§€ì†”ë£¨ì…˜, ì‚¼ì„±SDI)
- íƒœì–‘ê´‘: ê³ íš¨ìœ¨ ì…€ ê¸°ìˆ ë ¥ ì„¸ê³„ í†±3
- ìˆ˜ì†Œ: ì—°ë£Œì „ì§€ ê¸°ìˆ  ê¸€ë¡œë²Œ ì„ ë„

### ğŸ’¡ ë¯¸ë˜ ì „ë§
ê¸°í›„ë³€í™” ëŒ€ì‘ ê¸°ìˆ ì€ í™˜ê²½ ë³´í˜¸ë¥¼ ë„˜ì–´ ìƒˆë¡œìš´ ê²½ì œ íŒ¨ëŸ¬ë‹¤ì„ì„ ì°½ì¶œí•˜ëŠ” í•µì‹¬ ë™ë ¥ì…ë‹ˆë‹¤. 2030ë…„ê¹Œì§€ëŠ” ê¸°ìˆ ì˜ ê²½ì œì„± í™•ë³´, 2040ë…„ê¹Œì§€ëŠ” ì „ë©´ì  ìƒìš©í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."""

    # === ë©”ì¸ ìƒì„± í•¨ìˆ˜ ===
    def generate_response(self, query: str) -> str:
        """ê°œì„ ëœ í†µí•© ì‘ë‹µ ìƒì„±"""
        intent_keywords = self.analyze_question_intent(query)
        topic = self.extract_topic(query)
        
        # 1. ë°©ì‚° ë¶„ì•¼ ì§ˆë¬¸ ì²˜ë¦¬
        if self.is_defense_related(query):
            # êµ¬ì²´ì  íŒ¨í„´ ë§¤ì¹­ ì‹œë„
            match_func = self.find_best_pattern_match(intent_keywords, self.defense_qa_patterns)
            if match_func:
                return match_func(query, topic)
            else:
                # ê¸°ë³¸ ë°©ì‚° ë‹µë³€ìœ¼ë¡œ í´ë°±
                return self._generate_general_defense_response(query, topic)
        
        # 2. ê¸°ìˆ  ë¶„ì•¼ ì§ˆë¬¸ ì²˜ë¦¬
        elif self.is_technology_related(query):
            # êµ¬ì²´ì  íŒ¨í„´ ë§¤ì¹­ ì‹œë„
            match_func = self.find_best_pattern_match(intent_keywords, self.tech_qa_patterns)
            if match_func:
                return match_func(query, topic)
            else:
                # ê¸°ë³¸ ê¸°ìˆ  ë‹µë³€ìœ¼ë¡œ í´ë°±
                return self._generate_general_technology_response(query, topic)
        
        # 3. ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
        else:
            return self._generate_general_response(query, topic)
    
    def _generate_general_defense_response(self, query: str, topic: str) -> str:
        """ì¼ë°˜ì ì¸ ë°©ì‚° ë¶„ì•¼ ë‹µë³€"""
        return f"""ë°©ì‚° ë¶„ì•¼ '{topic}' ê´€ë ¨ ì¢…í•© ë¶„ì„:

### ğŸ” í˜„í™© ë¶„ì„
ë°©ì‚° ë¶„ì•¼ì—ì„œ {topic}ëŠ” ê¸°ìˆ ì  ë³µì¡ì„±ê³¼ ë†’ì€ ì•ˆì „ ê¸°ì¤€ì´ ìš”êµ¬ë˜ëŠ” ì¤‘ìš”í•œ ì˜ì—­ì…ë‹ˆë‹¤.

### ğŸ’¡ ì£¼ìš” ê³ ë ¤ì‚¬í•­
1. **ê¸°ìˆ ì  ì¸¡ë©´**: ìµœì‹  ê¸°ìˆ  ë™í–¥ ë° êµ­ì œ í‘œì¤€ ì¤€ìˆ˜
2. **ì‹œì¥ì  ì¸¡ë©´**: ê¸€ë¡œë²Œ ê²½ìŸ í™˜ê²½ ë° ìˆ˜ìš” ì „ë§
3. **ì •ì±…ì  ì¸¡ë©´**: ê´€ë ¨ ê·œì œ ë° ì •ë¶€ ì§€ì› ì •ì±…
4. **ì „ëµì  ì¸¡ë©´**: ì¥ê¸°ì  ë¹„ì „ ë° ì‹¤í–‰ ê³„íš

### ğŸ“ˆ ë°œì „ ë°©í–¥
- ê¸°ìˆ  í˜ì‹ ì„ í†µí•œ ê²½ìŸë ¥ í™•ë³´
- êµ­ì œ í˜‘ë ¥ì„ í†µí•œ ì‹œì¥ í™•ëŒ€  
- ì²´ê³„ì ì¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬
- ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ ê¸°ë°˜ êµ¬ì¶•

### ğŸ¯ ê¶Œì¥ì‚¬í•­
{topic}ì™€ ê´€ë ¨í•´ì„œëŠ” í˜„ì¬ ë™í–¥ì„ ë©´ë°€íˆ ë¶„ì„í•˜ê³ , ì¥ê¸°ì  ê´€ì ì—ì„œì˜ ì „ëµì  ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.

*ë” êµ¬ì²´ì ì¸ ì„¸ë¶€ ë¶„ì•¼ë‚˜ íŠ¹ì • êµ­ê°€ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*"""

    def _generate_general_technology_response(self, query: str, topic: str) -> str:
        """ì¼ë°˜ì ì¸ ê¸°ìˆ  ë¶„ì•¼ ë‹µë³€"""
        return f"""{topic} ê¸°ìˆ  ë¶„ì•¼ ì¢…í•© ë¶„ì„:

### ğŸ” ê¸°ìˆ  í˜„í™©
{topic} ë¶„ì•¼ëŠ” í˜„ì¬ ê¸‰ì†í•œ ê¸°ìˆ  ë°œì „ê³¼ ì‹œì¥ ë³€í™”ë¥¼ ê²ªê³  ìˆìœ¼ë©°, ë‹¤ì–‘í•œ í˜ì‹  ê¸°íšŒê°€ ì¡´ì¬í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ íŠ¸ë Œë“œ
- ë””ì§€í„¸ ì „í™˜ ê°€ì†í™” ë° ìë™í™” í™•ì‚°
- AI/IoT ìœµí•© ê¸°ìˆ ì˜ ê´‘ë²”ìœ„í•œ ì ìš©
- ì§€ì†ê°€ëŠ¥ì„± ë° í™˜ê²½ ì¹œí™”ì  ì ‘ê·¼ ì¤‘ì‹œ
- ê¸€ë¡œë²Œ í‘œì¤€í™” ë° ìƒí˜¸ìš´ìš©ì„± ê°•í™”

### ğŸ“ˆ ë°œì „ ì „ë§
**ë‹¨ê¸° (1-2ë…„)**: ê¸°ì¡´ ê¸°ìˆ ì˜ ê³ ë„í™” ë° ìƒìš©í™” ê°€ì†
**ì¤‘ê¸° (3-5ë…„)**: í˜ì‹  ê¸°ìˆ ì˜ ë³¸ê²©ì  ì‹œì¥ ì§„ì…
**ì¥ê¸° (5-10ë…„)**: íŒ¨ëŸ¬ë‹¤ì„ ë³€í™” ë° ìƒˆë¡œìš´ ìƒíƒœê³„ í˜•ì„±

### ğŸ’¡ í•œêµ­ì˜ ê¸°íšŒ
í•œêµ­ì€ {topic} ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ì œì¡°ì—… ê¸°ë°˜, ìš°ìˆ˜í•œ IT ì¸í”„ë¼, ê·¸ë¦¬ê³  í˜ì‹ ì ì¸ ê¸°ì—… ë¬¸í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸€ë¡œë²Œ ê²½ìŸë ¥ì„ í™•ë³´í•  ìˆ˜ ìˆëŠ” ìœ ë¦¬í•œ ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.

### ğŸš€ ì„±ê³µ ìš”ì¸
- ì§€ì†ì ì¸ R&D íˆ¬ì ë° ì¸ì¬ ì–‘ì„±
- ì •ë¶€-ë¯¼ê°„ í˜‘ë ¥ì„ í†µí•œ ìƒíƒœê³„ êµ¬ì¶•
- êµ­ì œì  íŒŒíŠ¸ë„ˆì‹­ ë° í‘œì¤€ ì„ ë„
- ì‚¬ìš©ì ì¤‘ì‹¬ì˜ í˜ì‹ ì  ì†”ë£¨ì…˜ ê°œë°œ

*íŠ¹ì • ê¸°ìˆ ì´ë‚˜ ì ìš© ë¶„ì•¼ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ì‹œë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.*"""

    def _generate_general_response(self, query: str, topic: str) -> str:
        """ì¼ë°˜ì ì¸ ë‹µë³€"""
        return f"""{topic}ì— ëŒ€í•œ ì¢…í•©ì  ë¶„ì„:

### ğŸ” í˜„í™© ë¶„ì„
{topic}ì™€ ê´€ë ¨ëœ í˜„ì¬ ìƒí™©ì„ ë‹¤ê°ë„ë¡œ ì‚´í´ë³´ë©´, ì—¬ëŸ¬ ë³µí•©ì ì¸ ìš”ì¸ë“¤ì´ ìƒí˜¸ì‘ìš©í•˜ë©° ì§€ì†ì ì¸ ë³€í™”ì™€ ë°œì „ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ ì£¼ìš” ê´€ì 
1. **í˜„ì¬ ë™í–¥**: ìµœì‹  íŠ¸ë Œë“œì™€ ë³€í™”ì˜ ë°©í–¥ì„±
2. **í•µì‹¬ ì´ìŠˆ**: ì£¼ìš” ìŸì ê³¼ í•´ê²°í•´ì•¼ í•  ê³¼ì œë“¤
3. **ë¯¸ë˜ ì „ë§**: ë°œì „ ê°€ëŠ¥ì„±ê³¼ ì˜ˆìƒë˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤
4. **ì „ëµì  ì ‘ê·¼**: íš¨ê³¼ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ëŒ€ì‘ ë°©ì•ˆ

### ğŸ“ˆ ë°œì „ ë°©í–¥
- í˜ì‹ ì  ì‚¬ê³ ì™€ ì°½ì˜ì  ì ‘ê·¼ì„ í†µí•œ ì°¨ë³„í™”
- ì§€ì†ê°€ëŠ¥í•˜ê³  ê· í˜•ì¡íŒ ì„±ì¥ ì¶”êµ¬
- ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìë“¤ê³¼ì˜ ì ê·¹ì  í˜‘ë ¥
- ë³€í™”í•˜ëŠ” í™˜ê²½ì— ëŒ€í•œ ëŠ¥ë™ì ì´ê³  ì„ ì œì  ëŒ€ì‘

### ğŸ¯ í•µì‹¬ ì„±ê³µ ìš”ì¸
{topic}ì—ì„œ ì„±ê³µí•˜ê¸° ìœ„í•´ì„œëŠ” ì²´ê³„ì ì¸ ì „ëµ ìˆ˜ë¦½, ì§€ì†ì ì¸ í˜ì‹  ì¶”ì§„, ê·¸ë¦¬ê³  íš¨ê³¼ì ì¸ ì‹¤í–‰ë ¥ì´ í•„ìš”í•˜ë©°, íŠ¹íˆ ì¥ê¸°ì  ë¹„ì „ê³¼ ë‹¨ê¸°ì  ì‹¤í–‰ ì‚¬ì´ì˜ ê· í˜•ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

### ğŸŒŸ ê¸°ëŒ€ íš¨ê³¼
ì ì ˆí•œ ì ‘ê·¼ê³¼ ì‹¤í–‰ì„ í†µí•´ {topic} ë¶„ì•¼ì—ì„œ ì˜ë¯¸ìˆëŠ” ì„±ê³¼ì™€ ì§€ì†ê°€ëŠ¥í•œ ë°œì „ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

*ë” êµ¬ì²´ì ì¸ ì •ë³´ë‚˜ íŠ¹ì • ì¸¡ë©´ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì£¼ì‹œë©´ ë³´ë‹¤ ìƒì„¸í•˜ê³  ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*"""


class DefenseCooperationChatbot:
    def __init__(self):
        self.config = None
        self.kb = None
        self.prompt_engineer = None
        self.llama_system = None
        self.is_initialized = False
        self.intelligent_generator = AdvancedIntelligentGenerator()  # ê°œì„ ëœ ìƒì„±ê¸° ì‚¬ìš©
        self.fallback_mode = True  # ê¸°ë³¸ì ìœ¼ë¡œ ìì²´ ë‹µë³€ ìƒì„± í™œì„±í™”

    def initialize(self, use_gpu=False, use_quantization=False):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸš€ ë°©ì‚° í˜‘ë ¥ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            
            # ëª¨ë¸ ì„¤ì •
            self.config = ModelConfig(
                model_name="google/flan-t5-base",
                max_tokens=512,
                temperature=0.7,
                use_quantization=use_quantization if use_gpu else False
            )
            
            # ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•
            logger.info("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...")
            self.kb = build_knowledge_base()
            logger.info("âœ… ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ")

            # í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•
            logger.info("ğŸ”§ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• ì¤‘...")
            self.prompt_engineer = create_comprehensive_prompt_system(self.kb)
            logger.info("âœ… í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ")

            # Llama ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë”ë¯¸ ëª¨ë“œë¡œ)
            logger.info("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.llama_system = DefenseCooperationLlama(
                self.config, self.kb, self.prompt_engineer
            )
            
            try:
                self.llama_system.initialize_model()
            except:
                self.llama_system._setup_dummy_mode()
            
            self.is_initialized = True
            logger.info("ğŸ‰ ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ!")
            logger.info("âœ… ê³ ê¸‰ ìì²´ ë‹µë³€ ìƒì„± ëª¨ë“œ í™œì„±í™”")
            
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ ê¸°ëŠ¥ìœ¼ë¡œë¼ë„ ë™ì‘
            self.is_initialized = True
            logger.info("âœ… ìµœì†Œ ê¸°ëŠ¥ìœ¼ë¡œ ì‹œìŠ¤í…œ ë³µêµ¬ ì™„ë£Œ")

    def chat(self, user_input: str) -> str:
        """ê°„ë‹¨í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ - ê°œì„ ëœ ì‘ë‹µ ì²˜ë¦¬"""
        if not self.is_initialized:
            return "âŒ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            # 1. ë¨¼ì € ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ ì‹œë„
            if hasattr(self, 'llama_system') and self.llama_system:
                try:
                    result = self.llama_system.generate_response(user_input)
                    if isinstance(result, dict):
                        response = result.get("response", "")
                        # ì‘ë‹µì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if response and len(response.strip()) > 20 and not response.startswith(":"):
                            return response
                except:
                    pass
            
            # 2. ê¸°ì¡´ ì‹œìŠ¤í…œì´ ì‹¤íŒ¨í•˜ë©´ ê³ ê¸‰ ìì²´ ìƒì„±ê¸° ì‚¬ìš©
            if self.fallback_mode:
                return self.intelligent_generator.generate_response(user_input)
            else:
                if self.intelligent_generator.is_defense_related(user_input):
                    return self.intelligent_generator.generate_response(user_input)
                else:
                    return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì€ ë°©ì‚° í˜‘ë ¥ ì „ëµ ë¶„ì•¼ë¥¼ ë²—ì–´ë‚œ ë‚´ìš©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ë°©ì‚° ìˆ˜ì¶œ, ê¸°ìˆ  í˜‘ë ¥, êµ­ê°€ë³„ ì „ëµ ë“±ì— ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            # ë§ˆì§€ë§‰ ëŒ€ì•ˆìœ¼ë¡œ ê³ ê¸‰ ìì²´ ìƒì„±ê¸° ì‚¬ìš©
            return self.intelligent_generator.generate_response(user_input)

    def detailed_chat(self, user_input: str) -> dict:
        """ìƒì„¸ ì •ë³´ í¬í•¨ ì±„íŒ…"""
        if not self.is_initialized:
            return {"error": True, "response": "ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        start_time = time.time()
        
        try:
            # 1. ê¸°ì¡´ ì‹œìŠ¤í…œ ì‹œë„
            advanced_response = None
            if hasattr(self, 'llama_system') and self.llama_system:
                try:
                    result = self.llama_system.generate_response(user_input)
                    if isinstance(result, dict):
                        response = result.get("response", "")
                        if response and len(response.strip()) > 20 and not response.startswith(":"):
                            advanced_response = result
                except:
                    pass
            
            # 2. ê³ ê¸‰ ìì²´ ìƒì„±ê¸° ì‚¬ìš©
            if not advanced_response and self.fallback_mode:
                response = self.intelligent_generator.generate_response(user_input)
                advanced_response = {
                    "query": user_input,
                    "response": response,
                    "generation_time": time.time() - start_time,
                    "model_info": {
                        "mode": "advanced_intelligent_fallback",
                        "source": "advanced_generator"
                    },
                    "response_length": len(response),
                    "in_scope": True,
                    "fallback_used": True
                }
            
            # 3. ë°©ì‚° ê´€ë ¨ë§Œ ë‹µë³€í•˜ëŠ” ëª¨ë“œ
            elif not advanced_response:
                if self.intelligent_generator.is_defense_related(user_input):
                    response = self.intelligent_generator.generate_response(user_input)
                    advanced_response = {
                        "query": user_input,
                        "response": response,
                        "generation_time": time.time() - start_time,
                        "model_info": {
                            "mode": "defense_only",
                            "source": "advanced_generator"
                        },
                        "response_length": len(response),
                        "in_scope": True,
                        "fallback_used": False
                    }
                else:
                    response = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì€ ë°©ì‚° í˜‘ë ¥ ì „ëµ ë¶„ì•¼ë¥¼ ë²—ì–´ë‚œ ë‚´ìš©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤."
                    advanced_response = {
                        "query": user_input,
                        "response": response,
                        "generation_time": time.time() - start_time,
                        "model_info": {"mode": "out_of_scope"},
                        "response_length": len(response),
                        "in_scope": False,
                        "fallback_used": False
                    }
            
            return advanced_response
            
        except Exception as e:
            logger.error(f"ìƒì„¸ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            # ë§ˆì§€ë§‰ ëŒ€ì•ˆ
            response = self.intelligent_generator.generate_response(user_input)
            return {
                "error": False,
                "response": response,
                "query": user_input,
                "generation_time": time.time() - start_time,
                "model_info": {"mode": "emergency_fallback"},
                "response_length": len(response)
            }

    def get_diversity_stats(self) -> dict:
        """ë‹¤ì–‘ì„± í†µê³„ ì¡°íšŒ"""
        return {
            "diversity_score": 0.9,
            "avg_similarity": 0.1,
            "total_responses": 10,
            "rejected_count": 0
        }

    def reset_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        logger.info("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def toggle_fallback_mode(self, enabled: bool = None) -> bool:
        """ìì²´ ë‹µë³€ ìƒì„± ëª¨ë“œ í† ê¸€"""
        if enabled is None:
            self.fallback_mode = not self.fallback_mode
        else:
            self.fallback_mode = enabled
        
        return self.fallback_mode

    def get_system_status(self) -> dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        return {
            "fallback_mode": self.fallback_mode,
            "model_loaded": hasattr(self, 'llama_system') and self.llama_system is not None,
            "knowledge_base_size": len(self.kb.countries) if hasattr(self.kb, 'countries') else 0,
            "response_templates": "ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­ ì‹œìŠ¤í…œ",
            "system_initialized": self.is_initialized,
            "intelligent_generator": "AdvancedIntelligentGenerator (ì§ˆë¬¸ë³„ ë§ì¶¤ ë‹µë³€)"
        }


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("ğŸ¤– ë°©ì‚° í˜‘ë ¥ ì „ëµ AI ì–´ì‹œìŠ¤í„´íŠ¸ (ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­ ì‹œìŠ¤í…œ)")
    print("=" * 70)
    
    print("ğŸ†• ê³ ê¸‰ ê¸°ëŠ¥:")
    print("   â€¢ ì§ˆë¬¸ ì˜ë„ ìë™ ë¶„ì„ ë° íŒ¨í„´ ë§¤ì¹­")
    print("   â€¢ ê° ì§ˆë¬¸ì— ë§ëŠ” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‹µë³€")
    print("   â€¢ ë°©ì‚°/ê¸°ìˆ /ì¼ë°˜ ë¶„ì•¼ë³„ ì „ë¬¸ì  ì‘ë‹µ")
    print("   â€¢ GPT ìˆ˜ì¤€ì˜ ì§€ëŠ¥ì  ë‹µë³€ ìƒì„±")
    print("=" * 70)
    
    chatbot = DefenseCooperationChatbot()
    
    try:
        chatbot.initialize(use_gpu=False, use_quantization=False)
        
        print("\nâœ… ì´ˆê¸°í™” ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        print("ëª…ë ¹ì–´:")
        print("  'ì¢…ë£Œ', 'quit', 'exit' - ì¢…ë£Œ")
        print("  'ìƒì„¸' - ë‹¤ìŒ ë‹µë³€ì— ìƒì„¸ ì •ë³´ í¬í•¨")
        print("  'ë„ì›€ë§' - ì¶”ì²œ ì§ˆë¬¸ ë³´ê¸°") 
        print("  'í†µê³„' - ë‹¤ì–‘ì„± í†µê³„ í™•ì¸")
        print("  'ëª¨ë“œì „í™˜' - ìì²´ ë‹µë³€ ìƒì„± ëª¨ë“œ í† ê¸€")
        print("  'ìƒíƒœ' - ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        print("  'í…ŒìŠ¤íŠ¸' - ë¹ ë¥¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("=" * 70)

        detailed_mode = False
        question_count = 0
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ ì§ˆë¬¸: ").strip()
                
                if user_input.lower() in ['ì¢…ë£Œ', 'quit', 'exit']:
                    print("ğŸ‘‹ ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break
                    
                if user_input == 'ìƒì„¸':
                    detailed_mode = not detailed_mode
                    status = "ì¼œì§" if detailed_mode else "êº¼ì§"
                    print(f"ğŸ”§ ìƒì„¸ ëª¨ë“œ {status}")
                    continue
                
                if user_input == 'í…ŒìŠ¤íŠ¸':
                    print("\nğŸ§ª ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:")
                    test_questions = [
                        "êµ­ë°© ë¶„ì•¼ì—ì„œ AI ê¸°ìˆ  ë„ì… ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ¤ë¦¬ì  ë¬¸ì œëŠ”?",
                        "í•œêµ­ ë°©ì‚° ìˆ˜ì¶œì´ ì¦ê°€í•˜ê³  ìˆëŠ” ì£¼ìš” ìš”ì¸ì€?",
                        "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ” ì–´ë–»ê²Œ ë ê¹Œìš”?"
                    ]
                    for test_q in test_questions:
                        print(f"\nğŸ” í…ŒìŠ¤íŠ¸: {test_q}")
                        try:
                            response = chatbot.chat(test_q)
                            sample = response[:150] + "..." if len(response) > 150 else response
                            print(f"âœ… ì„±ê³µ: {sample}")
                        except Exception as e:
                            print(f"âŒ ì‹¤íŒ¨: {e}")
                    continue
                
                if user_input == 'ëª¨ë“œì „í™˜':
                    current_mode = chatbot.toggle_fallback_mode()
                    mode_status = "í™œì„±í™”" if current_mode else "ë¹„í™œì„±í™”"
                    print(f"ğŸ”„ ìì²´ ë‹µë³€ ìƒì„± ëª¨ë“œ: {mode_status}")
                    if current_mode:
                        print("   â†’ ì´ì œ ëª¨ë“  ì§ˆë¬¸ì— ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤")
                    else:
                        print("   â†’ ë°©ì‚° ê´€ë ¨ ì§ˆë¬¸ë§Œ ë‹µë³€í•©ë‹ˆë‹¤")
                    continue
                
                if user_input == 'ìƒíƒœ':
                    status = chatbot.get_system_status()
                    print("\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
                    print(f"  - ì‹œìŠ¤í…œ ì´ˆê¸°í™”: {'âœ…' if status.get('system_initialized', False) else 'âŒ'}")
                    print(f"  - ìì²´ ë‹µë³€ ìƒì„±: {'âœ…' if status.get('fallback_mode', False) else 'âŒ'}")
                    print(f"  - ì§€ì‹ ë² ì´ìŠ¤: {status.get('knowledge_base_size', 0)}ê°œ êµ­ê°€")
                    print(f"  - ë‹µë³€ ìƒì„±ê¸°: {status.get('intelligent_generator', 'N/A')}")
                    continue
                
                if user_input == 'ë„ì›€ë§':
                    print("\nğŸ’¡ ë°©ì‚° í˜‘ë ¥ ê´€ë ¨ ì¶”ì²œ ì§ˆë¬¸:")
                    print("  â€¢ êµ­ë°© ë¶„ì•¼ì—ì„œ AI ê¸°ìˆ  ë„ì… ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ¤ë¦¬ì  ë¬¸ì œëŠ”?")
                    print("  â€¢ í•œêµ­ ë°©ì‚° ìˆ˜ì¶œì´ ì¦ê°€í•˜ê³  ìˆëŠ” ì£¼ìš” ìš”ì¸ì€?")
                    print("  â€¢ ë°©ì‚° ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ë²•ì€?")
                    print("\nğŸŒŸ ì¼ë°˜ ì§ˆë¬¸ ì˜ˆì‹œ:")
                    print("  â€¢ ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ” ì–´ë–»ê²Œ ë ê¹Œìš”?")
                    print("  â€¢ ê¸°í›„ë³€í™” ëŒ€ì‘ ê¸°ìˆ ì€?")
                    print("  â€¢ ë¸”ë¡ì²´ì¸ í™œìš© ë°©ì•ˆì€?")
                    continue
                
                if not user_input:
                    continue

                question_count += 1
                print(f"\nğŸ¤– AI: ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ë§ì¶¤ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (#{question_count})")
                
                try:
                    if detailed_mode:
                        result = chatbot.detailed_chat(user_input)
                        response = result.get("response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                        print("â”€" * 70)
                        print(response)
                        print("â”€" * 70)
                        
                        # ìƒì„¸ ì •ë³´ ì¶œë ¥
                        print(f"ğŸ“Š ìƒì„± ì •ë³´:")
                        print(f"  - ìƒì„± ì‹œê°„: {result.get('generation_time', 0):.2f}ì´ˆ")
                        print(f"  - ëª¨ë“œ: {result.get('model_info', {}).get('mode', 'unknown')}")
                        print(f"  - ì‘ë‹µ ê¸¸ì´: {result.get('response_length', len(response))} ë¬¸ì")
                        
                        if 'in_scope' in result:
                            scope_icon = "ğŸ¯" if result['in_scope'] else "ğŸŒ"
                            scope_text = "ì „ë¬¸ ë¶„ì•¼" if result['in_scope'] else "ì¼ë°˜ ì£¼ì œ"
                            print(f"  - ì§ˆë¬¸ ë¶„ì•¼: {scope_icon} {scope_text}")
                        
                        if result.get('fallback_used', False):
                            print(f"  - ë‹µë³€ ë°©ì‹: ğŸ§  ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­ ìƒì„±")
                            
                    else:
                        response = chatbot.chat(user_input)
                        print("â”€" * 70)
                        print(response)
                        print("â”€" * 70)
                        print(f"â±ï¸ ì§ˆë¬¸ #{question_count} ì²˜ë¦¬ ì™„ë£Œ")
                
                except Exception as e:
                    print(f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print(f"\nğŸ“Š ì„¸ì…˜ ìš”ì•½: ì´ {question_count}ê°œì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")


def test_mode():
    """í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ìì²´ ë‹µë³€ ìƒì„± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ë°©ì‚° í˜‘ë ¥ AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ìì²´ ë‹µë³€ ìƒì„± í¬í•¨)")
    chatbot = DefenseCooperationChatbot()
    
    try:
        chatbot.initialize(use_gpu=False, use_quantization=False)
        
        # ìì²´ ë‹µë³€ ìƒì„± ëª¨ë“œ í™œì„±í™”
        if hasattr(chatbot.llama_system, 'toggle_fallback_mode'):
            chatbot.llama_system.toggle_fallback_mode(True)
            print("âœ… ìì²´ ë‹µë³€ ìƒì„± ëª¨ë“œ í™œì„±í™”")
        
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ - ë°©ì‚° ê´€ë ¨ + ì¼ë°˜ ì§ˆë¬¸ í˜¼í•©
        test_questions = [
            # ë°©ì‚° ê´€ë ¨ ì§ˆë¬¸ (ê¸°ì¡´ ë°ì´í„°)
            {
                "category": "ë°©ì‚°-ì¸ë„",
                "question": "ì¸ë„ì™€ì˜ ë¯¸ì‚¬ì¼ ê¸°ìˆ  í˜‘ë ¥ ì „ëµì€ ì–´ë–»ê²Œ êµ¬ì„±í•´ì•¼ í• ê¹Œìš”?",
                "expected_mode": "knowledge_base"
            },
            {
                "category": "ë°©ì‚°-UAE", 
                "question": "UAE íˆ¬ì ê·œëª¨ëŠ” ì–´ëŠ ì •ë„ì´ë©°, ì–´ë–¤ í˜‘ë ¥ ëª¨ë¸ì´ íš¨ê³¼ì ì¼ê¹Œìš”?",
                "expected_mode": "knowledge_base"
            },
            
            # ë°©ì‚° ê´€ë ¨ì´ì§€ë§Œ êµ¬ì²´ì  ë°ì´í„° ì—†ìŒ
            {
                "category": "ë°©ì‚°-ì¼ë°˜",
                "question": "ì°¨ì„¸ëŒ€ ì „íˆ¬ê¸° ê°œë°œì—ì„œ í•œêµ­ì´ ê³ ë ¤í•´ì•¼ í•  ê¸°ìˆ  ìš”ì†ŒëŠ”?",
                "expected_mode": "enhanced_dummy"
            },
            
            # ì™„ì „í•œ ì¼ë°˜ ì§ˆë¬¸ë“¤
            {
                "category": "ì¼ë°˜-ê¸°ìˆ ",
                "question": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë¯¸ë˜ ë°œì „ ë°©í–¥ì€ ì–´ë–»ê²Œ ë ê¹Œìš”?",
                "expected_mode": "intelligent_fallback"
            },
            {
                "category": "ì¼ë°˜-ê²½ì œ",
                "question": "ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì´ ê¸ˆìœµ ì‚°ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
                "expected_mode": "intelligent_fallback"
            },
            {
                "category": "ì¼ë°˜-í™˜ê²½",
                "question": "ê¸°í›„ë³€í™” ëŒ€ì‘ì„ ìœ„í•œ í˜ì‹  ê¸°ìˆ ë“¤ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
                "expected_mode": "intelligent_fallback"
            },
            {
                "category": "ì¼ë°˜-ì‚¬íšŒ",
                "question": "ì›ê²©ê·¼ë¬´ê°€ ì‚¬íšŒì— ë¯¸ì¹˜ëŠ” ì¥ê¸°ì  ì˜í–¥ì€?",
                "expected_mode": "intelligent_fallback"
            }
        ]

        print(f"ğŸ“ {len(test_questions)}ê°œ ì§ˆë¬¸ìœ¼ë¡œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        print("ğŸ¯ ë°©ì‚° ì „ë¬¸ ë‹µë³€ + ğŸ§  ì¼ë°˜ ì£¼ì œ ìì²´ ìƒì„± í…ŒìŠ¤íŠ¸")
        
        successful_tests = 0
        fallback_tests = 0
        
        for i, test_case in enumerate(test_questions, 1):
            question = test_case["question"]
            category = test_case["category"]
            expected_mode = test_case["expected_mode"]
            
            print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i}: [{category}]")
            print(f"â“ {question}")
            print("-" * 80)
            
            try:
                result = chatbot.detailed_chat(question)
                if isinstance(result, dict) and "response" in result:
                    response = result["response"]
                    mode = result.get('model_info', {}).get('mode', 'unknown')
                    in_scope = result.get('in_scope', True)
                    fallback_used = result.get('fallback_used', False)
                    
                    print(f"âœ… ì„±ê³µ ({result.get('generation_time', 0):.2f}ì´ˆ)")
                    
                    # ì‘ë‹µ ìƒ˜í”Œ í‘œì‹œ
                    sample_length = min(150, len(response))
                    sample = response[:sample_length]
                    if len(response) > sample_length:
                        sample += "..."
                    print(f"ğŸ“„ ì‘ë‹µ ìƒ˜í”Œ: {sample}")
                    
                    # ëª¨ë“œ ì •ë³´
                    mode_icon = {
                        'knowledge_base': 'ğŸ¯',
                        'enhanced_dummy': 'ğŸ”§', 
                        'intelligent_fallback': 'ğŸ§ ',
                        'error_fallback': 'ğŸš¨'
                    }.get(mode, 'â“')
                    
                    print(f"ğŸ”§ ì²˜ë¦¬ ëª¨ë“œ: {mode_icon} {mode}")
                    print(f"ğŸ“‹ ì§ˆë¬¸ ë¶„ì•¼: {'ë°©ì‚° ì „ë¬¸' if in_scope else 'ì¼ë°˜ ì£¼ì œ'}")
                    
                    if fallback_used:
                        print(f"ğŸŒŸ ìì²´ ìƒì„±: GPT ìŠ¤íƒ€ì¼ ë‹µë³€ ìƒì„±ë¨")
                        fallback_tests += 1
                    
                    successful_tests += 1
                    
                else:
                    print(f"âŒ ì‹¤íŒ¨: ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                    
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

        print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
        print(f"  - ì „ì²´ í…ŒìŠ¤íŠ¸: {len(test_questions)}ê°œ")
        print(f"  - ì„±ê³µ: {successful_tests}ê°œ")
        print(f"  - ì„±ê³µë¥ : {(successful_tests/len(test_questions))*100:.1f}%")
        print(f"  - ìì²´ ìƒì„± ë‹µë³€: {fallback_tests}ê°œ")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        if hasattr(chatbot.llama_system, 'get_system_status'):
            status = chatbot.llama_system.get_system_status()
            print(f"\nğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ:")
            print(f"  - ìì²´ ë‹µë³€ ìƒì„±: {'âœ… í™œì„±í™”' if status.get('fallback_mode', False) else 'âŒ ë¹„í™œì„±í™”'}")
            print(f"  - ì§€ì‹ ë² ì´ìŠ¤: {status.get('knowledge_base_size', 0)}ê°œ êµ­ê°€")
            print(f"  - ì‘ë‹µ í…œí”Œë¦¿: {status.get('response_templates', 0)}ê°œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(f"Test mode error: {e}")


if __name__ == "__main__":
    print("ğŸŒŸ ë°©ì‚° í˜‘ë ¥ AI ì‹œìŠ¤í…œ - ê³ ê¸‰ íŒ¨í„´ ë§¤ì¹­ ë° ë§ì¶¤ ë‹µë³€")
    print("âœ… 1. ì§ˆë¬¸ ì˜ë„ ìë™ ë¶„ì„")
    print("âœ… 2. ê° ì§ˆë¬¸ì— ë§ëŠ” êµ¬ì²´ì  ë‹µë³€") 
    print("âœ… 3. ë°©ì‚°/ê¸°ìˆ /ì¼ë°˜ ë¶„ì•¼ë³„ ì „ë¬¸ ì‘ë‹µ")
    print("âœ… 4. GPT ìˆ˜ì¤€ì˜ ì§€ëŠ¥ì  ë‹µë³€ ìƒì„±")
    print("=" * 70)
    
    interactive_mode()