import streamlit as st
import sys
import os
from dotenv import load_dotenv
import time
import logging

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def initialize_custom_system():
    """ìì²´ ë°©ì‚° í˜‘ë ¥ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        from src.chatbot import DefenseCooperationChatbot
        
        if 'custom_chatbot' not in st.session_state:
            with st.spinner('ğŸš€ ë°©ì‚° í˜‘ë ¥ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...'):
                chatbot = DefenseCooperationChatbot()
                chatbot.initialize(use_gpu=False, use_quantization=False)
                
                if chatbot.is_initialized:
                    st.session_state.custom_chatbot = chatbot
                    st.success('âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!')
                    return True
                else:
                    st.error('âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨')
                    return False
        return True
        
    except ImportError as e:
        st.error(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
        st.error("src í´ë”ì˜ ëª¨ë“  íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return False
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return False

def initialize_openai_system(api_key):
    """OpenAI ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        st.session_state.openai_client = client
        return True
    except Exception as e:
        st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def get_custom_response(user_input):
    """ìì²´ ì‹œìŠ¤í…œ ì‘ë‹µ ìƒì„±"""
    try:
        chatbot = st.session_state.custom_chatbot
        result = chatbot.detailed_chat(user_input)
        
        if isinstance(result, dict) and "response" in result:
            return {
                "response": result["response"],
                "generation_time": result.get("generation_time", 0),
                "mode": result.get("model_info", {}).get("mode", "unknown"),
                "response_length": result.get("response_length", 0)
            }
        else:
            return {"response": str(result), "generation_time": 0}
            
    except Exception as e:
        logger.error(f"Custom response error: {e}")
        return {"response": f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", "generation_time": 0}

def get_openai_response(messages, model="gpt-3.5-turbo"):
    """OpenAI ì‘ë‹µ ìƒì„±"""
    try:
        client = st.session_state.openai_client
        
        # ë°©ì‚° í˜‘ë ¥ ì „ë¬¸ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        system_message = {
            "role": "system", 
            "content": """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë°©ì‚°ê¸°ìˆ  ìˆ˜ì¶œ í™•ëŒ€ë¥¼ ìœ„í•œ êµ­ê°€ë³„ í˜‘ë ¥ ì „ëµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            
ì£¼ìš” ì „ë¬¸ ë¶„ì•¼:
- ë¹„NATO êµ­ê°€(ì¸ë„, UAE, ë¸Œë¼ì§ˆ, ë™ë‚¨ì•„ì‹œì•„ ë“±)ì™€ì˜ ë°©ì‚° í˜‘ë ¥ ì „ëµ
- êµ­ê°€ë³„ êµ­ë°© ëŠ¥ë ¥ ë° ê¸°ìˆ  ì—­ëŸ‰ ë¶„ì„  
- ë°©ì‚° ìˆ˜ì¶œ ì‹œì¥ ë¶„ì„ ë° íˆ¬ì ìˆ˜ìµì„± í‰ê°€
- ë‹¨ê³„ë³„ í˜‘ë ¥ ë¡œë“œë§µ ë° ì •ì±… ì œì–¸

ì‘ë‹µ ì›ì¹™:
1. êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì œê³µ
2. ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµê³¼ ë‹¨ê³„ë³„ ë°©ì•ˆ ì œì‹œ
3. ê¸°íšŒì™€ ë¦¬ìŠ¤í¬ë¥¼ ê· í˜•ìˆê²Œ í‰ê°€
4. ì¥ê¸°ì  ê´€ì ì—ì„œ êµ­ê°€ ì´ìµ ê³ ë ¤"""
        }
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ ì „ì²´ ëŒ€í™”
        full_messages = [system_message] + messages
        
        response = client.chat.completions.create(
            model=model,
            messages=full_messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        logger.error(f"OpenAI response error: {e}")
        return f"OpenAI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í•œêµ­ ë°©ì‚° í˜‘ë ¥ ì „ëµ AI ì±—ë´‡",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # AI ì‹œìŠ¤í…œ ì„ íƒ
    ai_system = st.radio(
        "AI ì‹œìŠ¤í…œ ì„ íƒ:",
        ["ìì²´ ë°©ì‚° í˜‘ë ¥ AI", "OpenAI GPT-3.5"],
        help="ìì²´ ì‹œìŠ¤í…œ: ë°©ì‚° í˜‘ë ¥ ì „ë¬¸ ì§€ì‹ë² ì´ìŠ¤ í™œìš©\nOpenAI: ë²”ìš© AI ëª¨ë¸ ì‚¬ìš©"
    )
    
    st.divider()
    
    # API í‚¤ ì„¤ì •
    if ai_system == "OpenAI GPT-3.5":
        # .env íŒŒì¼ì—ì„œ ë¨¼ì € í™•ì¸
        env_openai_key = os.getenv('OPENAI_API_KEY')
        
        if env_openai_key:
            st.success("âœ… .env íŒŒì¼ì—ì„œ OpenAI API í‚¤ ê°ì§€ë¨")
            openai_api_key = env_openai_key
        else:
            openai_api_key = st.text_input(
                "OpenAI API Key:", 
                type="password",
                help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë˜ëŠ” .env íŒŒì¼ì— OPENAI_API_KEYë¡œ ì €ì¥)"
            )
        
        if openai_api_key:
            if initialize_openai_system(openai_api_key):
                st.success("âœ… OpenAI ì—°ê²° ì™„ë£Œ")
            system_ready = bool(openai_api_key)
        else:
            st.info("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ .env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”")
            system_ready = False
    
    else:
        # ìì²´ ì‹œìŠ¤í…œ ì‚¬ìš©
        huggingface_token = os.getenv('HUGGINGFACE_TOKEN')
        if huggingface_token:
            st.success("âœ… HuggingFace í† í° ê°ì§€ë¨")
        else:
            st.warning("âš ï¸ .env íŒŒì¼ì— HUGGINGFACE_TOKENì´ ì—†ìŠµë‹ˆë‹¤")
        
        system_ready = initialize_custom_system()
    
    st.divider()
    
    # ì‹œìŠ¤í…œ ì •ë³´
    st.subheader("ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ")
    if ai_system == "ìì²´ ë°©ì‚° í˜‘ë ¥ AI":
        st.write("""
        **ì „ë¬¸ ì§ˆë¬¸ ì˜ˆì‹œ:**
        - ì¸ë„ì™€ì˜ ë¯¸ì‚¬ì¼ ê¸°ìˆ  í˜‘ë ¥ ì „ëµì€?
        - UAE íˆ¬ì ê·œëª¨ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?
        - ë¸Œë¼ì§ˆê³¼ í•­ê³µìš°ì£¼ í˜‘ë ¥ì´ ê°€ëŠ¥í•œê°€ìš”?
        - ë™ë‚¨ì•„ì‹œì•„ í•´ì–‘ì•ˆë³´ í˜‘ë ¥ ë°©ì•ˆì€?
        """)
    else:
        st.write("""
        **OpenAI GPT-3.5 ì‚¬ìš©:**
        - ë°©ì‚° í˜‘ë ¥ ì „ë¬¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©
        - ë²”ìš© ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        - ì‹¤ì‹œê°„ ì¸í„°ë„· ì •ë³´ ì ‘ê·¼ ë¶ˆê°€
        """)

# ë©”ì¸ í˜ì´ì§€
st.title("ğŸ›¡ï¸ í•œêµ­ ë°©ì‚° í˜‘ë ¥ ì „ëµ AI ì±—ë´‡")
st.markdown("""
**ëŒ€í•œë¯¼êµ­ ë°©ì‚°ê¸°ìˆ  ìˆ˜ì¶œ í™•ëŒ€ë¥¼ ìœ„í•œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸**

ì´ ì±—ë´‡ì€ ë¹„NATO êµ­ê°€ë“¤ê³¼ì˜ ë°©ì‚° í˜‘ë ¥ ì „ëµ, ì‹œì¥ ë¶„ì„, íˆ¬ì ìˆ˜ìµì„± í‰ê°€ ë“±ì— ëŒ€í•œ 
ì „ë¬¸ì ì¸ ë¶„ì„ê³¼ ì œì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
""")

# ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
if system_ready:
    if ai_system == "ìì²´ ë°©ì‚° í˜‘ë ¥ AI":
        st.success("ğŸš€ ìì²´ ë°©ì‚° í˜‘ë ¥ AI ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.success("ğŸ¤– OpenAI GPT-3.5 ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
else:
    st.error("âŒ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # ìì²´ ì‹œìŠ¤í…œì˜ ê²½ìš° ì¶”ê°€ ì •ë³´ í‘œì‹œ
        if message["role"] == "assistant" and "metadata" in message:
            metadata = message["metadata"]
            with st.expander("ğŸ“Š ì‘ë‹µ ìƒì„¸ ì •ë³´"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ìƒì„± ì‹œê°„", f"{metadata.get('generation_time', 0):.2f}ì´ˆ")
                with col2:
                    st.metric("ì‘ë‹µ ê¸¸ì´", f"{metadata.get('response_length', 0)} ë¬¸ì")
                with col3:
                    st.metric("ëª¨ë“œ", metadata.get('mode', 'unknown'))

# ì±„íŒ… ì…ë ¥
if prompt := st.chat_input("ë°©ì‚° í˜‘ë ¥ ì „ëµì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” ë¶„ì„ ì¤‘..."):
            start_time = time.time()
            
            if ai_system == "ìì²´ ë°©ì‚° í˜‘ë ¥ AI":
                # ìì²´ ì‹œìŠ¤í…œ ì‚¬ìš©
                result = get_custom_response(prompt)
                response = result["response"]
                
                # ì‘ë‹µ í‘œì‹œ
                st.markdown(response)
                
                # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                generation_time = time.time() - start_time
                with st.expander("ğŸ“Š ì‘ë‹µ ìƒì„¸ ì •ë³´"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ìƒì„± ì‹œê°„", f"{generation_time:.2f}ì´ˆ")
                    with col2:
                        st.metric("ì‘ë‹µ ê¸¸ì´", f"{len(response)} ë¬¸ì")
                    with col3:
                        st.metric("ëª¨ë“œ", result.get('mode', 'enhanced_dummy'))
                
                # ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "metadata": {
                        "generation_time": generation_time,
                        "response_length": len(response),
                        "mode": result.get('mode', 'enhanced_dummy')
                    }
                })
                
            else:
                # OpenAI ì‚¬ìš©
                messages_for_api = [
                    {"role": m["role"], "content": m["content"]} 
                    for m in st.session_state.messages[:-1]  # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì œì™¸
                ]
                messages_for_api.append({"role": "user", "content": prompt})
                
                response = get_openai_response(messages_for_api)
                
                # ì‘ë‹µ í‘œì‹œ
                st.markdown(response)
                
                # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                generation_time = time.time() - start_time
                with st.expander("ğŸ“Š ì‘ë‹µ ìƒì„¸ ì •ë³´"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ìƒì„± ì‹œê°„", f"{generation_time:.2f}ì´ˆ")
                    with col2:
                        st.metric("ì‘ë‹µ ê¸¸ì´", f"{len(response)} ë¬¸ì")
                
                # ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "metadata": {
                        "generation_time": generation_time,
                        "response_length": len(response),
                        "mode": "openai_gpt35"
                    }
                })

# í•˜ë‹¨ ì •ë³´
st.divider()
col1, col2, col3 = st.columns(3)

with col1:
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

with col2:
    if ai_system == "ìì²´ ë°©ì‚° í˜‘ë ¥ AI" and 'custom_chatbot' in st.session_state:
        try:
            stats = st.session_state.custom_chatbot.get_diversity_stats()
            st.metric("ë‹¤ì–‘ì„± ì ìˆ˜", f"{stats.get('diversity_score', 0):.2f}")
        except:
            pass

with col3:
    st.metric("ì´ ëŒ€í™” ìˆ˜", len([m for m in st.session_state.messages if m["role"] == "user"]))

# í‘¸í„°
st.markdown("""
---
**ğŸ›¡ï¸ í•œêµ­ ë°©ì‚° í˜‘ë ¥ ì „ëµ AI ì±—ë´‡** | 
ë°©ì‚° ê¸°ìˆ  ìˆ˜ì¶œ í™•ëŒ€ë¥¼ ìœ„í•œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ | 
Made with Streamlit & ğŸ‡°ğŸ‡·
""")